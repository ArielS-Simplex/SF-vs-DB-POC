{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a9d4157-42ce-4125-9002-5fd2a1043df6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Utility Classes"
    }
   },
   "outputs": [],
   "source": [
    "%run ./data_utility_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fc07f00-a75a-44d1-aa58-d46429719ef5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Schema Configuration"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"schema_config.json\", \"r\") as file:\n",
    "    schema_config = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68aee42a-ad9a-4a04-8c04-212fa569bb8c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Retrieve Widget Parameters for Job Configuration"
    }
   },
   "outputs": [],
   "source": [
    "# Get widgets\n",
    "\n",
    "source_folder = dbutils.widgets.get(\"source_folder\")\n",
    "table_name = dbutils.widgets.get(\"table_name\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "table_keys = dbutils.widgets.get(\"table_keys\")\n",
    "job_name = dbutils.widgets.get(\"job_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "589eb47c-ae63-4c74-a42c-1c5c7f585a31",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initialize Schema and Add ETL Table"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Initialize SchemaManager\n",
    "schema_mgr = SchemaManager(spark)\n",
    "\n",
    "# Define schema\n",
    "schema_dict = schema_config[schema]\n",
    "\n",
    "# Get the current catalog name\n",
    "current_catalog = spark.catalog.currentCatalog()\n",
    "\n",
    "# Define metadata updates\n",
    "silver_metadata_updates = {\n",
    "    \"checkpoint\": '2025-06-01 00:00:00',\n",
    "    \"source_table\": f\"{current_catalog}.ncp.{table_name}_bronze\",\n",
    "    \"table_keys\": table_keys\n",
    "}\n",
    "\n",
    "bronze_metadata_updates = {\"table_keys\": table_keys, \"checkpoint\": '2020-01-01 00:00:00'}\n",
    "\n",
    "\n",
    "tables = [\n",
    "    (f\"{current_catalog}.ncp.{table_name}_bronze\", bronze_metadata_updates),\n",
    "    (f\"{current_catalog}.ncp.{table_name}_silver\", silver_metadata_updates),\n",
    "]\n",
    "\n",
    "# Insert bronze table metadata\n",
    "for schema_name, metadata in tables:\n",
    "    schema_mgr.add_new_table_etl(schema_name, schema_dict, metadata)\n",
    "    # Print results\n",
    "    display(\n",
    "        spark.sql(\n",
    "            f\"select * from {current_catalog}.ncp.metadata_table where table_name = '{schema_name}'\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b535c9ba-f494-4f73-806c-e19119ce869e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Delta Tables with Schema and Properties"
    }
   },
   "outputs": [],
   "source": [
    "for schema_name, metadata in tables:\n",
    "    table_keys = metadata.get(\"table_keys\", None)\n",
    "    table_properties = f\"TBLPROPERTIES (primaryKey='{table_keys}')\" if table_keys else \"\"\n",
    "    spark.sql(\n",
    "        f\"\"\"\n",
    "        CREATE TABLE {schema_name} ({', '.join([f'{col} {dtype}' for col, dtype in schema_dict.items()])})\n",
    "        USING DELTA {table_properties}\n",
    "        \"\"\"\n",
    "    )\n",
    "    # Check if the table was created\n",
    "    table_exists = spark.catalog.tableExists(schema_name)\n",
    "    if table_exists:\n",
    "        print(f\"Table {schema_name} was successfully created.\")\n",
    "    else:\n",
    "        print(f\"Failed to create table {schema_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5d6b609-5a12-480b-a6d7-7c9c525dc635",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Generate Workflow"
    }
   },
   "outputs": [],
   "source": [
    "from databricks_api import DatabricksAPI\n",
    "\n",
    "# Get the Databricks instance and token\n",
    "DATABRICKS_INSTANCE = (\n",
    "    dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\n",
    ")\n",
    "DATABRICKS_TOKEN = (\n",
    "    dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    ")\n",
    "\n",
    "current_user = (\n",
    "    dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    ")\n",
    "\n",
    "# Define the volume path and paramters\n",
    "volume_path = \"abfss://analytics-data@mlanalyticsstore01.dfs.core.windows.net/nuvei-simplex-sftp-nuvei-user/NCP\"\n",
    "source_path = f\"{volume_path}/{source_folder}\"\n",
    "bronze_table = f\"{current_catalog}.ncp.{table_name}_bronze\"\n",
    "silver_table = f\"{current_catalog}.ncp.{table_name}_silver\"\n",
    "\n",
    "# Initialize Databricks API client\n",
    "db = DatabricksAPI(host=f\"{DATABRICKS_INSTANCE}\", token=f\"{DATABRICKS_TOKEN}\")\n",
    "\n",
    "# Define the workflow JSON\n",
    "workflow_json = {\n",
    "    \"name\": job_name,\n",
    "    \"email_notifications\": {\n",
    "        \"on_failure\": [f\"{current_user}\"],\n",
    "        \"no_alert_for_skipped_runs\": True,\n",
    "    },\n",
    "    \"webhook_notifications\": {},\n",
    "    \"timeout_seconds\": 0,\n",
    "    \"max_concurrent_runs\": 1,\n",
    "    \"tasks\": [\n",
    "        {\n",
    "            \"task_key\": \"bronze_auto_loader\",\n",
    "            \"run_if\": \"ALL_SUCCESS\",\n",
    "            \"notebook_task\": {\n",
    "                \"notebook_path\": \"src/ncp_pipelines/generic_etls/bronze_auto_loader\",\n",
    "                \"base_parameters\": {\n",
    "                    \"SOURCE_PATH\": source_path,\n",
    "                    \"TARGET_TABLE\": bronze_table,\n",
    "                    \"OPERATIONAL_VOLUME\": f\"/Volumes/{current_catalog}/default/operational/prod\",\n",
    "                },\n",
    "                \"source\": \"GIT\",\n",
    "            },\n",
    "            \"job_cluster_key\": \"fraud_feature\",\n",
    "            \"max_retries\": 0,\n",
    "            \"min_retry_interval_millis\": 900000,\n",
    "            \"retry_on_timeout\": False,\n",
    "            \"disable_auto_optimization\": True,\n",
    "            \"timeout_seconds\": 0,\n",
    "            \"email_notifications\": {},\n",
    "            \"webhook_notifications\": {},\n",
    "        },\n",
    "        {\n",
    "            \"task_key\": \"silver_batch_etl\",\n",
    "            \"depends_on\": [{\"task_key\": \"bronze_auto_loader\"}],\n",
    "            \"run_if\": \"ALL_SUCCESS\",\n",
    "            \"notebook_task\": {\n",
    "                \"notebook_path\": \"src/ncp_pipelines/generic_etls/silver_batch_etl\",\n",
    "                \"base_parameters\": {\"TARGET_TABLE\": silver_table},\n",
    "                \"source\": \"GIT\",\n",
    "            },\n",
    "            \"max_retries\": 0,\n",
    "            \"min_retry_interval_millis\": 900000,\n",
    "            \"retry_on_timeout\": False,\n",
    "            \"disable_auto_optimization\": True,\n",
    "            \"timeout_seconds\": 0,\n",
    "            \"email_notifications\": {},\n",
    "            \"webhook_notifications\": {},\n",
    "        },\n",
    "    ],\n",
    "    \"git_source\": {\n",
    "        \"git_url\": \"https://dev.azure.com/nuvei/AI%20Analytics/_git/databricks_etls\",\n",
    "        \"git_provider\": \"azureDevOpsServices\",\n",
    "        \"git_branch\": \"main\",\n",
    "    },\n",
    "    \"tags\": {\"job_name\": job_name, \"team\": \"bpa\", \"type\": \"ncp_ingestion\"},\n",
    "    # \"run_as\": {\"service_principal_name\": \"ef2a4258-8195-4d34-8e97-99fad4c1d1b5\"},\n",
    "}\n",
    "\n",
    "# Create the workflow\n",
    "result = db.jobs.create_job(**workflow_json)\n",
    "print(result)\n",
    "# job_id = result[\"job_id\"]\n",
    "\n",
    "# # Update the workflow\n",
    "# workflow_json[\"run_as\"] = {\"service_principal_name\": \"ef2a4258-8195-4d34-8e97-99fad4c1d1b5\"}\n",
    "# update = db.jobs.update_job(job_id=job_id, new_settings=workflow_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3d70b50-be91-460e-92a1-6333138ac520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk.service.jobs import JobSettings as Job\n",
    "\n",
    "fraud_features_ingestion = Job.from_dict(\n",
    "    {\n",
    "        \"name\": job_name,\n",
    "        \"email_notifications\": {\n",
    "            \"on_failure\": [\n",
    "                current_user,\n",
    "            ],\n",
    "            \"no_alert_for_skipped_runs\": True,\n",
    "        },\n",
    "        \"tasks\": [\n",
    "            {\n",
    "                \"task_key\": \"bronze_auto_loader\",\n",
    "                \"notebook_task\": {\n",
    "                    \"notebook_path\": \"src/ncp_pipelines/generic_etls/bronze_auto_loader\",\n",
    "                    \"base_parameters\": {\n",
    "                        \"SOURCE_PATH\": source_path,\n",
    "                        \"TARGET_TABLE\": bronze_table,\n",
    "                        \"OPERATIONAL_VOLUME\": f\"/Volumes/{current_catalog}/default/operational/prod\",\n",
    "                    },\n",
    "                    \"source\": \"GIT\",\n",
    "                },\n",
    "                \"job_cluster_key\": table_name,\n",
    "                \"max_retries\": 1,\n",
    "                \"min_retry_interval_millis\": 900000,\n",
    "            },\n",
    "            {\n",
    "                \"task_key\": \"silver_batch_etl\",\n",
    "                \"depends_on\": [\n",
    "                    {\n",
    "                        \"task_key\": \"bronze_auto_loader\",\n",
    "                    },\n",
    "                ],\n",
    "                \"notebook_task\": {\n",
    "                    \"notebook_path\": \"src/ncp_pipelines/generic_etls/silver_batch_etl\",\n",
    "                    \"base_parameters\": {\n",
    "                        \"TARGET_TABLE\": silver_table,\n",
    "                    },\n",
    "                    \"source\": \"GIT\",\n",
    "                },\n",
    "                \"max_retries\": 1,\n",
    "                \"min_retry_interval_millis\": 900000,\n",
    "                \"disable_auto_optimization\": False,\n",
    "            },\n",
    "        ],\n",
    "        \"job_clusters\": [\n",
    "            {\n",
    "                \"job_cluster_key\": table_name,\n",
    "                \"new_cluster\": {\n",
    "                    \"spark_version\": \"16.4.x-scala2.13\",\n",
    "                    \"azure_attributes\": {\n",
    "                        \"first_on_demand\": 1,\n",
    "                        \"availability\": \"SPOT_WITH_FALLBACK_AZURE\",\n",
    "                        \"spot_bid_max_price\": 100,\n",
    "                    },\n",
    "                    \"node_type_id\": \"Standard_D8ds_v5\",\n",
    "                    \"spark_env_vars\": {\n",
    "                        \"PYSPARK_PYTHON\": \"/databricks/python3/bin/python3\",\n",
    "                    },\n",
    "                    \"policy_id\": \"001CFA1F0598B866\",\n",
    "                    \"data_security_mode\": \"SINGLE_USER\",\n",
    "                    \"runtime_engine\": \"STANDARD\",\n",
    "                    \"kind\": \"CLASSIC_PREVIEW\",\n",
    "                    \"is_single_node\": False,\n",
    "                    \"autoscale\": {\n",
    "                        \"min_workers\": 1,\n",
    "                        \"max_workers\": 4,\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "        \"git_source\": {\n",
    "            \"git_url\": \"https://dev.azure.com/nuvei/AI%20Analytics/_git/databricks_etls\",\n",
    "            \"git_provider\": \"azureDevOpsServices\",\n",
    "            \"git_branch\": \"main\",\n",
    "        },\n",
    "        \"tags\": {\n",
    "            \"job_name\": job_name,\n",
    "            \"team\": \"bpa\",\n",
    "            \"type\": \"ncp_ingestion\",\n",
    "        },\n",
    "        \"performance_target\": \"PERFORMANCE_OPTIMIZED\",\n",
    "    }\n",
    ")\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "w.jobs.create(**fraud_features_ingestion.as_shallow_dict())\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "databricks_api"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5385920463355271,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "create_new_etl",
   "widgets": {
    "job_name": {
     "currentValue": "apms_ingestion",
     "nuid": "745c9f99-846e-4d97-9b8f-2475439af6cf",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Job Name",
      "name": "job_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Job Name",
      "name": "job_name",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "apms",
     "nuid": "5a540bc2-eaf9-4556-a1a6-fbe6dd0e323e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Schema",
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Schema",
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "source_folder": {
     "currentValue": "bpa.STP_GetAPMTransactions",
     "nuid": "5b261755-70b6-4334-88a5-6724b460e294",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Source Folder",
      "name": "source_folder",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Source Folder",
      "name": "source_folder",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "table_keys": {
     "currentValue": "apm_request_id,apm_request_date,transaction_main_id,transaction_date",
     "nuid": "0233ad66-16cc-4ae9-950f-7b4fc5741b1f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Table Keys",
      "name": "table_keys",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Table Keys",
      "name": "table_keys",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "table_name": {
     "currentValue": "apms",
     "nuid": "da45b2f9-4ce3-4fbc-a69e-088c49561834",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Table Name",
      "name": "table_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Table Name",
      "name": "table_name",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
