{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c556878-8682-4c00-9caf-7b600e14f32e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Defining Boolean Columns with PySpark Enum and Types"
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pyspark.sql.types import (\n",
    "    ByteType,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    TimestampType,\n",
    "    BooleanType,\n",
    "    FloatType\n",
    ")\n",
    "\n",
    "TEST_CLIENTS = ['test multi','davidh test2 multi','ice demo multi', 'monitoring client pod2 multi']\n",
    "\n",
    "BOOLEAN_STRING_COLUMN = ['is_currency_converted', 'is_eea', 'is_external_mpi', 'is_partial_amount', 'is_prepaid',\n",
    "                         'is_sale_3d', 'is_void', 'liability_shift', 'manage_3d_decision', 'mc_scheme_token_used',\n",
    "                         'partial_approval_is_void', 'rebill', 'is_3d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2468807-ebdc-402a-a1c6-7427142c7a40",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importing Required Libraries and Functions for PySpark"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any, Dict, Optional\n",
    "from pyspark.sql import functions as F, DataFrame\n",
    "from pyspark.sql.functions import col, when, isnan\n",
    "from pyspark.sql.functions import col, when, regexp_extract, lower, trim, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "112b904b-cd39-452d-a8b0-9ea24f4e33a4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Creating New Transaction Status Columns with PySpark"
    }
   },
   "outputs": [],
   "source": [
    "def create_conversions_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Creates new columns in the DataFrame based on specific conditions and transformations.\n",
    "    Adds flags for transaction status, challenge success, exemption logic, frictionless logic,\n",
    "    successful authentication, approval, and decline logic.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame with raw transaction data.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with additional columns based on the specified logic.\n",
    "    \"\"\"\n",
    "    existing_cols = df.columns\n",
    "    new_cols = {}\n",
    "\n",
    "    # --- 1. Conditional copies ---\n",
    "    new_cols[\"is_sale_3d_auth_3d\"] = F.when(\n",
    "        F.col(\"transaction_type\") == \"auth3d\", F.col(\"is_sale_3d\")\n",
    "    )\n",
    "    new_cols[\"manage_3d_decision_auth_3d\"] = F.when(\n",
    "        F.col(\"transaction_type\") == \"auth3d\", F.col(\"manage_3d_decision\")\n",
    "    )\n",
    "\n",
    "    # --- 2. Transaction result status flags ---\n",
    "    status_map = {\n",
    "        \"init_status\": \"initauth3d\",\n",
    "        \"auth_3d_status\": \"auth3d\",\n",
    "        \"sale_status\": \"sale\",\n",
    "        \"auth_status\": \"auth\",\n",
    "        \"settle_status\": \"settle\",\n",
    "        \"verify_auth_3d_status\": \"verify_auth_3d\",\n",
    "    }\n",
    "\n",
    "    for new_col, txn_type in status_map.items():\n",
    "        new_cols[new_col] = F.when(\n",
    "            F.col(\"transaction_type\") == txn_type,\n",
    "            F.when(F.col(\"transaction_result_id\") == \"1006\", F.lit(\"true\")).otherwise(\n",
    "                F.lit(\"false\")\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # --- 3. Challenge success ---\n",
    "    new_cols[\"is_successful_challenge\"] = F.when(\n",
    "        F.col(\"3d_flow_status\") == \"3d_success\", F.lit(\"true\")\n",
    "    ).when(\n",
    "        F.col(\"3d_flow_status\").isin(\"3d_failure\", \"3d_wasnt_completed\"), F.lit(\"false\")\n",
    "    )\n",
    "\n",
    "    # --- 4. Exemption logic ---\n",
    "    new_cols[\"is_successful_exemption\"] = F.when(\n",
    "        F.col(\"authentication_flow\") == \"exemption\", F.lit(\"true\")\n",
    "    ).when(F.col(\"challenge_preference\") == \"y_requested_by_acquirer\", F.lit(\"false\"))\n",
    "\n",
    "    # --- 5. Frictionless logic ---\n",
    "    new_cols[\"is_successful_frictionless\"] = F.when(\n",
    "        (F.col(\"authentication_flow\") == \"frictionless\") & (F.col(\"status\") == \"40\"),\n",
    "        F.lit(\"true\"),\n",
    "    ).when(F.col(\"authentication_flow\") == \"frictionless\", F.lit(\"false\"))\n",
    "\n",
    "    # --- 6. Successful authentication ---\n",
    "    new_cols[\"is_successful_authentication\"] = F.when(\n",
    "        (F.col(\"3d_flow_status\") == \"3d_success\")\n",
    "        | (\n",
    "            (F.col(\"authentication_flow\") == \"frictionless\") & (F.col(\"status\") == \"40\")\n",
    "        ),\n",
    "        F.lit(\"true\"),\n",
    "    ).when(\n",
    "        (F.col(\"acs_url\").isNotNull()) & (F.col(\"authentication_flow\") != \"exemption\")\n",
    "        | (\n",
    "            (F.col(\"authentication_flow\") == \"frictionless\") & (F.col(\"status\") != \"40\")\n",
    "        ),\n",
    "        F.lit(\"false\"),\n",
    "    )\n",
    "\n",
    "    # --- 7. Approval logic ---\n",
    "    new_cols[\"is_approved\"] = F.when(\n",
    "        (F.col(\"auth_status\") == \"true\") | (F.col(\"sale_status\") == \"true\"),\n",
    "        F.lit(\"true\"),\n",
    "    ).when(\n",
    "        (F.col(\"auth_status\") == \"false\") | (F.col(\"sale_status\") == \"false\"),\n",
    "        F.lit(\"false\"),\n",
    "    )\n",
    "\n",
    "    # --- 8. Decline logic ---\n",
    "    new_cols[\"is_declined\"] = F.when(\n",
    "        (F.col(\"transaction_type\").isin(\"sale\", \"auth\"))\n",
    "        & (F.col(\"transaction_result_id\") == \"1008\"),\n",
    "        F.lit(\"true\"),\n",
    "    ).when(\n",
    "        F.col(\"auth_status\").isNotNull() | F.col(\"sale_status\").isNotNull(),\n",
    "        F.lit(\"false\"),\n",
    "    )\n",
    "\n",
    "    # --- Final projection ---\n",
    "    # Keep all existing columns and add new ones\n",
    "    final_cols = [F.col(col_name) for col_name in existing_cols] + [\n",
    "        expr.alias(new_col) for new_col, expr in new_cols.items()\n",
    "    ]\n",
    "\n",
    "    return df.select(*final_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e80e8bbf-1008-4bb6-8c2d-7075f163f1e0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Normalizing and Casting DataFrame Columns"
    }
   },
   "outputs": [],
   "source": [
    "def fixing_dtypes(df: DataFrame, schema: StructType) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Fixes the data types of the columns in the DataFrame based on the provided schema.\n",
    "    Normalizes boolean strings, trims and lowers string columns, and handles null values.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame with raw data.\n",
    "        schema (StructType): Schema defining the expected data types of the columns.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with corrected data types.\n",
    "    \"\"\"\n",
    "    struct_fields_dict = {f.name: f for f in schema.fields}\n",
    "    \n",
    "    # bool_conversion_dict = {\n",
    "    #     \"1\": \"true\",\n",
    "    #     \"1.0\": \"true\",\n",
    "    #     \"true\": \"true\",\n",
    "    #     \"yes\": \"true\",\n",
    "    #     \"0\": \"false\",\n",
    "    #     \"0.0\": \"false\",\n",
    "    #     \"false\": \"false\",\n",
    "    #     \"no\": \"false\",\n",
    "    # }\n",
    "    # bool_keys = list(bool_conversion_dict.keys())\n",
    "\n",
    "    columns_to_force_null = {\n",
    "        \"user_agent_3d\",\n",
    "        \"authentication_request\",\n",
    "        \"authentication_response\",\n",
    "        \"authorization_req_duration\",\n",
    "    }\n",
    "\n",
    "    new_cols = []\n",
    "\n",
    "    for field in schema.fieldNames():\n",
    "        if field in columns_to_force_null:\n",
    "            new_cols.append(lit(None).cast(schema[field].dataType).alias(field))\n",
    "            continue\n",
    "\n",
    "        expr = col(field)\n",
    "        field_type = struct_fields_dict[field].dataType\n",
    "        \n",
    "        valid_true  = [\"true\", \"1\", \"yes\", \"1.0\"]\n",
    "        valid_false = [\"false\", \"0\", \"no\", \"0.0\"]\n",
    "\n",
    "        if field_type == BooleanType() or field in BOOLEAN_STRING_COLUMN:\n",
    "            # Normalize first\n",
    "            expr_norm = trim(lower(expr))\n",
    "            \n",
    "            # Only allow values that are valid booleans\n",
    "            expr = when(expr_norm.isin(*valid_true), lit(True)) \\\n",
    "                .when(expr_norm.isin(*valid_false), lit(False)) \\\n",
    "                .otherwise(lit(None))\n",
    "            \n",
    "            expr = expr.cast(BooleanType())\n",
    "\n",
    "        elif isinstance(field_type, StringType):\n",
    "            expr = when(expr.rlike(r\"^\\d+\\.?\\d*$\"), regexp_extract(expr, r\"(\\d+)\", 1)).otherwise(expr)\n",
    "            expr = trim(lower(expr))\n",
    "            expr = when(expr.isin([\"<na>\", \"na\", \"nan\", \"none\", \"\", \" \", \"\\x00\"]), None).otherwise(expr)\n",
    "            expr = when(expr == \"deprecated\", None).otherwise(expr)\n",
    "\n",
    "        else:\n",
    "            if isinstance(field_type, (FloatType, DoubleType)):\n",
    "                expr = when(expr.isNull(), lit(float(\"nan\"))).otherwise(expr)\n",
    "            expr = expr.cast(field_type)\n",
    "\n",
    "        new_cols.append(expr.alias(field))\n",
    "\n",
    "    # Also select any additional columns in the DataFrame that are not part of the schema\n",
    "    passthrough_cols = [col(c) for c in df.columns if c not in schema.fieldNames()]\n",
    "    return df.select(*new_cols, *passthrough_cols)\n",
    "\n",
    "def filter_and_transform_transactions(df, schema=None):\n",
    "    \"\"\"\n",
    "    Filters and transforms the transactions DataFrame.\n",
    "    Removes test clients, fixes data types, and creates new transaction status columns.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame with raw transaction data.\n",
    "        schema (StructType, optional): Schema defining the expected data types of the columns.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Transformed DataFrame with filtered and processed transactions.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.filter(~col(\"multi_client_name\").isin(TEST_CLIENTS))\n",
    "    df = create_conversions_columns(df)\n",
    "    df = fixing_dtypes(df, schema)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4644935254936662,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "custom_etl_functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
